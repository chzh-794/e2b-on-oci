#!/bin/bash

set -euo pipefail

exec > >(tee /var/log/e2b-client-user-data.log | logger -t e2b-client-user-data -s 2>/dev/console) 2>&1

echo "================================================================================"
echo "E2B Client Pool Bootstrap"
echo "Environment: ${environment}"
echo "Prefix: ${prefix}"
echo "Compartment: ${compartment_id}"
echo "Region: ${region}"
echo "================================================================================"

# Wait for apt locks and retry apt operations to avoid race conditions with cloud-init
wait_for_apt() {
  for i in {1..60}; do
    if ! sudo fuser /var/lib/apt/lists/lock /var/lib/dpkg/lock-frontend /var/lib/dpkg/lock >/dev/null 2>&1; then
      return 0
    fi
    echo "Waiting for apt locks (attempt $i)..."
    sleep 5
  done
  return 1
}

apt_install_with_retry() {
  local max_attempts=5
  for attempt in $(seq 1 $max_attempts); do
    wait_for_apt || continue
    if sudo apt-get update -y && sudo apt-get install -y "$@"; then
      return 0
    fi
    echo "apt install failed (attempt $attempt/$max_attempts), retrying..."
    sleep 10
  done
  echo "ERROR: apt install failed after $max_attempts attempts"
  return 1
}

apt_install_with_retry python3-pip jq gzip nfs-common nftables nbd-client
pip3 install --upgrade oci-cli
export PATH="$PATH:/usr/local/bin"
sudo systemctl stop docker docker.socket >/dev/null 2>&1 || true
sudo apt remove -y docker-ce docker-ce-cli docker-buildx-plugin docker-compose-plugin containerd containerd.io >/dev/null 2>&1 || true
wait_for_apt
sudo DEBIAN_FRONTEND=noninteractive apt install -y docker.io
sudo systemctl daemon-reload
sudo systemctl enable --now docker.socket
sudo systemctl restart docker || sudo systemctl start docker
sudo usermod -aG docker ubuntu || true

# Add root (Nomad agent user) to disk and kvm groups for NBD device access
# This is required for orchestrator to access /dev/nbd* devices in Nomad raw_exec allocations
# POC fix from POC_SUMMARY.md section "### 5. NBD Device Permissions"
sudo usermod -a -G disk,kvm root || true

cat <<'EOF' >/etc/profile.d/e2b-client-env.sh
export E2B_ENVIRONMENT="${environment}"
export E2B_PREFIX="${prefix}"
export E2B_REGION="${region}"
export E2B_COMPARTMENT_ID="${compartment_id}"
export CONSUL_GOSSIP_ENCRYPTION_KEY="${consul_gossip_encryption_key}"
EOF

chmod +x /etc/profile.d/e2b-client-env.sh

export OCI_CLI_AUTH=instance_principal

# Configure NBD module parameters persistently
sudo mkdir -p /etc/modprobe.d
sudo tee /etc/modprobe.d/nbd.conf >/dev/null <<'EOF'
options nbd max_part=16 nbds_max=128
EOF

sudo modprobe -r nbd || true
sudo modprobe nbd
sudo sysctl -w kernel.unprivileged_userns_clone=1

# Mount /run/netns as shared for named network namespace support
# This is required for netns.NewNamed() to work (used by orchestrator for sandbox network isolation)
# /var/run/netns is a symlink to /run/netns
# Create systemd service to ensure /run/netns is mounted as shared on boot
sudo mkdir -p /var/run/netns /run/netns
sudo tee /etc/systemd/system/e2b-netns.service >/dev/null <<'EOF'
[Unit]
Description=Mount /run/netns as shared for network namespace support
After=local-fs.target
Before=network.target

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/bin/bash -c 'mount --make-shared /run 2>/dev/null || true; umount /run/netns 2>/dev/null || true; mount -t tmpfs -o shared tmpfs /run/netns'
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
EOF
sudo systemctl daemon-reload
sudo systemctl enable e2b-netns.service
sudo systemctl start e2b-netns.service

# Grant CAP_SYS_ADMIN to unshare, bash, ip, losetup, and mount binaries for Firecracker namespace isolation
# This allows nomad user to:
# - Run 'unshare -pf' and perform tmpfs mounts inside the unshare namespace
# - Create network namespaces via 'ip netns add' (which requires mount permissions for /run/netns)
# - Mount ext4 filesystems via 'mount -o loop' (mount internally uses losetup, so losetup needs CAP_SYS_ADMIN)
sudo setcap cap_sys_admin+ep /usr/bin/unshare || true
sudo setcap cap_sys_admin+ep /usr/bin/bash || true
sudo setcap cap_sys_admin+ep /usr/bin/ip || true
sudo setcap cap_sys_admin+ep /usr/sbin/losetup || true
sudo setcap cap_sys_admin+ep /usr/bin/mount || true

sudo mkdir -p /opt/consul/bin /opt/nomad/bin /opt/e2b/runtime /orchestrator /var/e2b/templates /fc-envd /fc-kernels /fc-versions /mnt/disks/fc-envs/v1
sudo chmod 0755 /opt/consul /opt/nomad /opt/e2b /opt/e2b/runtime /orchestrator
sudo chown -R ubuntu:ubuntu /var/e2b /fc-envd /mnt/disks/fc-envs

sudo tee /usr/local/bin/e2b-cleanup-network.sh >/dev/null <<'EOF'
#!/usr/bin/env bash
set -euo pipefail

cleanup_namespaces() {
  mapfile -t namespaces < <(ip netns list 2>/dev/null | awk '{print $1}')
  for ns in "$${namespaces[@]}"; do
    [[ "$${ns}" == ns-* ]] || continue

    if [[ -n "$(ip netns pids "$${ns}" 2>/dev/null)" ]]; then
      continue
    fi

    idx="$${ns#ns-}"
    ip link delete "veth-$${idx}" >/dev/null 2>&1 || true
    ip netns delete "$${ns}" >/dev/null 2>&1 || true
  done
}

cleanup_nbd() {
  shopt -s nullglob
  for pid_file in /sys/block/nbd*/pid; do
    dev="$(basename "$(dirname "$${pid_file}")")"
    pid="$(cat "$${pid_file}")"

    if [[ "$${pid}" -eq 0 ]]; then
      nbd-client -d "/dev/$${dev}" >/dev/null 2>&1 || true
      continue
    fi

    if ! ps -p "$${pid}" >/dev/null 2>&1; then
      nbd-client -d "/dev/$${dev}" >/dev/null 2>&1 || true
    fi
  done
}

cleanup_namespaces
cleanup_nbd
EOF

sudo chmod +x /usr/local/bin/e2b-cleanup-network.sh

sudo tee /etc/systemd/system/e2b-cleanup-network.service >/dev/null <<'EOF'
[Unit]
Description=Cleanup stale E2B network namespaces and NBD devices
After=network.target

[Service]
Type=oneshot
ExecStart=/usr/local/bin/e2b-cleanup-network.sh
EOF

sudo tee /etc/systemd/system/e2b-cleanup-network.timer >/dev/null <<'EOF'
[Unit]
Description=Run E2B network cleanup periodically

[Timer]
OnBootSec=2min
OnUnitActiveSec=1min
AccuracySec=30s
Persistent=true

[Install]
WantedBy=timers.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable --now e2b-cleanup-network.timer

echo "${consul_run_script_b64}" | base64 --decode | gunzip >/opt/consul/bin/run-consul.sh
echo "${consul_client_run_script_b64}" | base64 --decode | gunzip >/opt/consul/bin/run-consul-client.sh
echo "${nomad_run_script_b64}" | base64 --decode | gunzip >/opt/nomad/bin/run-nomad.sh
echo "${nomad_client_run_script_b64}" | base64 --decode | gunzip >/opt/nomad/bin/run-nomad-client.sh

chmod +x /opt/consul/bin/run-consul.sh /opt/consul/bin/run-consul-client.sh /opt/nomad/bin/run-nomad.sh /opt/nomad/bin/run-nomad-client.sh

WAN_IF=$(ip route get 8.8.8.8 | awk '{for(i=1;i<=NF;i++) if($i=="dev") {print $(i+1); exit}}')

# Enable IPv4 forwarding so Firecracker guests can reach the internet.
sudo sysctl -w net.ipv4.ip_forward=1
echo "net.ipv4.ip_forward = 1" | sudo tee /etc/sysctl.d/99-e2b-ipforward.conf >/dev/null

# Disable UFW firewall (OCI default) - it adds REJECT rules that block Firecracker VM traffic
# UFW adds "REJECT all" rules to FORWARD chain which prevents sandbox network connectivity
if command -v ufw >/dev/null 2>&1; then
  sudo ufw disable || true
  sudo systemctl stop ufw || true
  sudo systemctl disable ufw || true
fi

# Configure iptables (POC explicitly disabled nftables - see POC_SUMMARY.md)
# Flush and configure INPUT chain to allow intra-cluster communication
if command -v iptables >/dev/null 2>&1; then
  sudo iptables -F INPUT || true
  sudo iptables -P INPUT ACCEPT || true
  sudo iptables -F FORWARD || true
  sudo iptables -P FORWARD ACCEPT || true
  
  # Remove any UFW REJECT rules that might persist after UFW disable
  sudo iptables -D FORWARD -j REJECT --reject-with icmp-host-prohibited 2>/dev/null || true

  # Allow orchestrator and template-manager gRPC ports from VCN
  sudo iptables -I INPUT 1 -p tcp --dport 5008 -s 10.0.0.0/16 -j ACCEPT || true
  sudo iptables -I INPUT 1 -p tcp --dport 5009 -s 10.0.0.0/16 -j ACCEPT || true

  if [ -n "$${WAN_IF}" ]; then
    sudo iptables -t nat -A POSTROUTING -s 169.254.0.0/16 -o "$${WAN_IF}" -j MASQUERADE
    sudo iptables -t nat -A POSTROUTING -s 10.12.0.0/16 -o "$${WAN_IF}" -j MASQUERADE
    sudo iptables -I FORWARD 1 -i "$${WAN_IF}" -o veth+ -m state --state RELATED,ESTABLISHED -j ACCEPT || true
    sudo iptables -I FORWARD 1 -i veth+ -o "$${WAN_IF}" -j ACCEPT || true
  fi
fi

/opt/consul/bin/run-consul-client.sh \
  --gossip-encryption-key "${consul_gossip_encryption_key}" \
  --compartment-id "${compartment_id}" \
  --region "${region}" \
  --server-role "server"

/opt/nomad/bin/run-nomad-client.sh \
  --compartment-id "${compartment_id}" \
  --region "${region}" \
  --node-class "client" \
  --meta "pool = \"client\"" \
  --server-role "server" \
  --host-volume "/var/e2b/templates" \
  --host-volume-name "e2b-templates"

echo "Running initial network/NBD cleanup to seed slot pool..."
sudo /usr/local/bin/e2b-cleanup-network.sh || true

# Install template-manager systemd service (if binaries exist)
# This allows template-manager to auto-start on boot without requiring deploy-services.sh
# The service will only start if /opt/e2b/bin/template-manager exists (created by deploy-poc.sh Phase 2)
if [ -f /opt/e2b/bin/template-manager ]; then
  echo "Installing template-manager systemd service..."
  
  # Install systemd service file
  sudo tee /etc/systemd/system/template-manager.service >/dev/null <<'EOF'
[Unit]
Description=E2B Template Manager
Documentation=https://github.com/e2b-dev/infra
After=network-online.target consul.service
Wants=network-online.target
Requires=consul.service

[Service]
Type=simple
User=root
Group=root
WorkingDirectory=/opt/e2b
EnvironmentFile=-/opt/e2b/template-manager.env
# NODE_ID will be set dynamically from instance metadata or hostname
ExecStartPre=/bin/bash -c 'if [ -z "$NODE_ID" ]; then export NODE_ID=$(curl -sSL -H "Authorization: Bearer Oracle" http://169.254.169.254/opc/v2/instance/id 2>/dev/null || hostname); fi'
ExecStart=/bin/bash -c 'cd /opt/e2b && export NODE_ID=$${NODE_ID:-$$(hostname)} && set -a && source template-manager.env && set +a && exec ./bin/template-manager --port 5009 --proxy-port 15007'
ExecReload=/bin/kill -HUP $MAINPID
KillSignal=SIGTERM
Restart=on-failure
RestartSec=5s
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
EOF

  # Create Consul service definition (if Consul config directory exists)
  if [ -d /opt/consul/config ]; then
    sudo tee /opt/consul/config/template-manager.json >/dev/null <<'EOF'
{
  "service": {
    "name": "template-manager",
    "port": 5009,
    "tags": ["grpc"],
    "check": {
      "grpc": "127.0.0.1:5009",
      "interval": "10s",
      "timeout": "3s"
    }
  }
}
EOF
    sudo chown consul:consul /opt/consul/config/template-manager.json 2>/dev/null || sudo chown root:root /opt/consul/config/template-manager.json
  fi

  # Enable and start service (will start after binaries are deployed)
  sudo systemctl daemon-reload
  sudo systemctl enable template-manager || true
  # Don't start here - binaries may not exist yet, deploy-poc.sh Phase 2 will start it
else
  echo "template-manager binary not found, skipping systemd service installation (will be installed by deploy-services.sh)"
fi

echo "E2B client pool bootstrap completed."
